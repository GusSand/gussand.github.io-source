I"¸<p><strong>Under construction</strong>.</p>

<ul>
  <li>
    <p>Is NTK the only explanation? Almost surely not.</p>
  </li>
  <li>
    <p>The crux of NTK: weights don‚Äôt move very much from their (random) inits</p>
  </li>
  <li>
    <p>Therefore, meaningful feature learning does not happen!</p>
  </li>
  <li>
    <p>However, we know (both from visualizations as well as controlled experiments) that neural networks <em>do</em> learn features using GD.</p>
  </li>
  <li>
    <p><em>Hessian control</em>: a theory that explains dynamics ‚Äúfar away‚Äù from the initialization.</p>
  </li>
</ul>

<h2 class="label" id="setup">Setup</h2>

<h2 class="label" id="the-pl-condition">The PL* condition</h2>

<h2 class="label" id="hessian-control">Hessian control</h2>
:ET